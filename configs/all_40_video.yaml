pretrained_model_path: "./checkpoints/stable-diffusion-v1-4"
output_dir: "/content/drive/MyDrive/EEG2Video_checkpoints/videodiffusion"

train_data:
  video_path:
    - "/content/drive/MyDrive/Data/Raw/Video/1st_10min.mp4"
    - "/content/drive/MyDrive/Data/Raw/Video/2nd_10min.mp4"
    - "/content/drive/MyDrive/Data/Raw/Video/3rd_10min.mp4"
    - "/content/drive/MyDrive/Data/Raw/Video/4th_10min.mp4"
    # add 5th–7th if processed
  prompt:
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/1st_10min.txt"
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/2nd_10min.txt"
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/3rd_10min.txt"
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/4th_10min.txt"
    # add 5th–7th captions as needed
  n_sample_frames: 6
  width: 512
  height: 288
  sample_start_idx: 0
  sample_frame_rate: 2

validation_data:
  prompts:
    - "a person is running"
    - "a car is moving on the road"
    - "a dog in the water"
  video_length: 6
  width: 512
  height: 288
  num_inference_steps: 50
  guidance_scale: 12.5
  use_inv_latent: False
  num_inv_steps: 50

# LOW VALUES WILL BE UPDATED LATER
learning_rate: 3e-5
train_batch_size: 1
max_train_steps: 100
checkpointing_steps: 20
validation_steps: 20

trainable_modules:
  - "attn1.to_q"
  - "attn2.to_q"
  - "attn_temp"

seed: 33
mixed_precision: fp16
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: False
