pretrained_model_path: "./checkpoints/stable-diffusion-v1-4"
output_dir: "/content/drive/MyDrive/EEG2Video_checkpoints/videodiffusion"

train_data:
  video_path:
    - "/content/drive/MyDrive/Data/Raw/Video/1st_10min.mp4"
    - "/content/drive/MyDrive/Data/Raw/Video/2nd_10min.mp4"
    - "/content/drive/MyDrive/Data/Raw/Video/3rd_10min.mp4"
    - "/content/drive/MyDrive/Data/Raw/Video/4th_10min.mp4"
    # - "/content/drive/MyDrive/Data/Raw/Video/5th_10min.mp4"
    # - "/content/drive/MyDrive/Data/Raw/Video/6th_10min.mp4"
    # - "/content/drive/MyDrive/Data/Raw/Video/7th_10min.mp4"
  prompt:
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/1st_10min.txt"
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/2nd_10min.txt"
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/3rd_10min.txt"
    - "/content/drive/MyDrive/Data/Raw/BLIP-caption/4th_10min.txt"
    # - "/content/drive/MyDrive/Data/Raw/BLIP-caption/5th_10min.txt"
    # - "/content/drive/MyDrive/Data/Raw/BLIP-caption/6th_10min.txt"
    # - "/content/drive/MyDrive/Data/Raw/BLIP-caption/7th_10min.txt"
  n_sample_frames: 6
  width: 512
  height: 288
  sample_start_idx: 0
  sample_frame_rate: 2

validation_data:
  prompts:
    - "a person is running"
    - "a car is moving on the road"
    - "a dog in the water"
  video_length: 6
  width: 512
  height: 288
  num_inference_steps: 50
  guidance_scale: 12.5
  use_inv_latent: False
  num_inv_steps: 50

learning_rate: 3e-5
train_batch_size: 1
num_train_epochs: 5        # bump later
checkpointing_steps: 500
validation_steps: 500

trainable_modules:
  - "attn1.to_q"
  - "attn2.to_q"
  - "attn_temp"

seed: 33
mixed_precision: fp16
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True

# Optional: configure DANA beta here instead of hardcoding
dana_beta: 0.3
